{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-24 04:19:35.211203: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-24 04:19:36.061697: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras import callbacks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import callbacks\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# The following is another way to implement primary capsule layer. This is much slower.\\n# Apply Conv2D `n_channels` times and concatenate all capsules\\ndef PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\\n    outputs = []\\n    for _ in range(n_channels):\\n        output = layers.Conv2D(filters=dim_capsule, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\\n        outputs.append(layers.Reshape([output.get_shape().as_list()[1] ** 2, dim_capsule])(output))\\n    outputs = layers.Concatenate(axis=1)(outputs)\\n    return layers.Lambda(squash)(outputs)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import initializers, layers\n",
    "\n",
    "\n",
    "class Length(layers.Layer):\n",
    "    \"\"\"\n",
    "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss.\n",
    "    Using this layer as model's output can directly predict labels by using `y_pred = np.argmax(model.predict(x), 1)`\n",
    "    inputs: shape=[None, num_vectors, dim_vector]\n",
    "    output: shape=[None, num_vectors]\n",
    "    \"\"\"\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), -1) + K.epsilon())\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Length, self).get_config()\n",
    "        return config\n",
    "\n",
    "\n",
    "class Mask(layers.Layer):\n",
    "    \"\"\"\n",
    "    Mask a Tensor with shape=[None, num_capsule, dim_vector] either by the capsule with max length or by an additional \n",
    "    input mask. Except the max-length capsule (or specified capsule), all vectors are masked to zeros. Then flatten the\n",
    "    masked Tensor.\n",
    "    For example:\n",
    "        ```\n",
    "        x = keras.layers.Input(shape=[8, 3, 2])  # batch_size=8, each sample contains 3 capsules with dim_vector=2\n",
    "        y = keras.layers.Input(shape=[8, 3])  # True labels. 8 samples, 3 classes, one-hot coding.\n",
    "        out = Mask()(x)  # out.shape=[8, 6]\n",
    "        # or\n",
    "        out2 = Mask()([x, y])  # out2.shape=[8,6]. Masked with true labels y. Of course y can also be manipulated.\n",
    "        ```\n",
    "    \"\"\"\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if type(inputs) is list:  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n",
    "            assert len(inputs) == 2\n",
    "            inputs, mask = inputs\n",
    "        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n",
    "            # compute lengths of capsules\n",
    "            x = tf.sqrt(tf.reduce_sum(tf.square(inputs), -1))\n",
    "            # generate the mask which is a one-hot code.\n",
    "            # mask.shape=[None, n_classes]=[None, num_capsule]\n",
    "            mask = tf.one_hot(indices=tf.argmax(x, 1), depth=x.shape[1])\n",
    "\n",
    "        # inputs.shape=[None, num_capsule, dim_capsule]\n",
    "        # mask.shape=[None, num_capsule]\n",
    "        # masked.shape=[None, num_capsule * dim_capsule]\n",
    "        masked = K.batch_flatten(inputs * tf.expand_dims(mask, -1))\n",
    "        return masked\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if type(input_shape[0]) is tuple:  # true label provided\n",
    "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
    "        else:  # no true label provided\n",
    "            return tuple([None, input_shape[1] * input_shape[2]])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Mask, self).get_config()\n",
    "        return config\n",
    "\n",
    "\n",
    "def squash(vectors, axis=-1):\n",
    "    \"\"\"\n",
    "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
    "    :param vectors: some vectors to be squashed, N-dim tensor\n",
    "    :param axis: the axis to squash\n",
    "    :return: a Tensor with same shape as input vectors\n",
    "    \"\"\"\n",
    "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm) / tf.sqrt(s_squared_norm + K.epsilon())\n",
    "    return scale * vectors\n",
    "\n",
    "\n",
    "class CapsuleLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the\n",
    "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
    "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_capsule] and output shape = \\\n",
    "    [None, num_capsule, dim_capsule]. For Dense Layer, input_dim_capsule = dim_capsule = 1.\n",
    "    :param num_capsule: number of capsules in this layer\n",
    "    :param dim_capsule: dimension of the output vectors of the capsules in this layer\n",
    "    :param routings: number of iterations for the routing algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
    "        self.input_num_capsule = input_shape[1]\n",
    "        self.input_dim_capsule = input_shape[2]\n",
    "\n",
    "        # Transform matrix, from each input capsule to each output capsule, there's a unique weight as in Dense layer.\n",
    "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
    "                                        self.dim_capsule, self.input_dim_capsule],\n",
    "                                 initializer=self.kernel_initializer,\n",
    "                                 name='W')\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n",
    "        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule, 1]\n",
    "        inputs_expand = tf.expand_dims(tf.expand_dims(inputs, 1), -1)\n",
    "\n",
    "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
    "        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule, 1]\n",
    "        inputs_tiled = tf.tile(inputs_expand, [1, self.num_capsule, 1, 1, 1])\n",
    "\n",
    "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n",
    "        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n",
    "        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule, 1]\n",
    "        # Regard the first two dimensions as `batch` dimension, then\n",
    "        # matmul(W, x): [..., dim_capsule, input_dim_capsule] x [..., input_dim_capsule, 1] -> [..., dim_capsule, 1].\n",
    "        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "        inputs_hat = tf.squeeze(tf.map_fn(lambda x: tf.matmul(self.W, x), elems=inputs_tiled))\n",
    "\n",
    "        # Begin: Routing algorithm ---------------------------------------------------------------------#\n",
    "        # The prior for coupling coefficient, initialized as zeros.\n",
    "        # b.shape = [None, self.num_capsule, 1, self.input_num_capsule].\n",
    "        b = tf.zeros(shape=[500, self.num_capsule, 1, self.input_num_capsule])\n",
    "\n",
    "        assert self.routings > 0, 'The routings should be > 0.'\n",
    "        for i in range(self.routings):\n",
    "            # c.shape=[batch_size, num_capsule, 1, input_num_capsule]\n",
    "            c = tf.nn.softmax(b, axis=1)\n",
    "\n",
    "            # c.shape = [batch_size, num_capsule, 1, input_num_capsule]\n",
    "            # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
    "            # The first two dimensions as `batch` dimension,\n",
    "            # then matmal: [..., 1, input_num_capsule] x [..., input_num_capsule, dim_capsule] -> [..., 1, dim_capsule].\n",
    "            # outputs.shape=[None, num_capsule, 1, dim_capsule]\n",
    "            outputs = squash(tf.matmul(c, inputs_hat))  # [None, 10, 1, 16]\n",
    "\n",
    "            if i < self.routings - 1:\n",
    "                # outputs.shape =  [None, num_capsule, 1, dim_capsule]\n",
    "                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
    "                # The first two dimensions as `batch` dimension, then\n",
    "                # matmal:[..., 1, dim_capsule] x [..., input_num_capsule, dim_capsule]^T -> [..., 1, input_num_capsule].\n",
    "                # b.shape=[batch_size, num_capsule, 1, input_num_capsule]\n",
    "                b += tf.matmul(outputs, inputs_hat, transpose_b=True)\n",
    "        # End: Routing algorithm -----------------------------------------------------------------------#\n",
    "        print(outputs.shape)\n",
    "        return tf.squeeze(outputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'num_capsule': self.num_capsule,\n",
    "            'dim_capsule': self.dim_capsule,\n",
    "            'routings': self.routings\n",
    "        }\n",
    "        base_config = super(CapsuleLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
    "    \"\"\"\n",
    "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
    "    :param inputs: 4D tensor, shape=[None, width, height, channels]\n",
    "    :param dim_capsule: the dim of the output vector of capsule\n",
    "    :param n_channels: the number of types of capsules\n",
    "    :return: output tensor, shape=[None, num_capsule, dim_capsule]\n",
    "    \"\"\"\n",
    "    output = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
    "                           name='primarycap_conv2d')(inputs)\n",
    "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output)\n",
    "    return layers.Lambda(squash, name='primarycap_squash')(outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# The following is another way to implement primary capsule layer. This is much slower.\n",
    "# Apply Conv2D `n_channels` times and concatenate all capsules\n",
    "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
    "    outputs = []\n",
    "    for _ in range(n_channels):\n",
    "        output = layers.Conv2D(filters=dim_capsule, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n",
    "        outputs.append(layers.Reshape([output.get_shape().as_list()[1] ** 2, dim_capsule])(output))\n",
    "    outputs = layers.Concatenate(axis=1)(outputs)\n",
    "    return layers.Lambda(squash)(outputs)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "def CapsNet(input_shape, n_class, routings, batch_size):\n",
    "    \"\"\"\n",
    "    A Capsule Network on MNIST.\n",
    "    :param input_shape: data shape, 3d, [width, height, channels]\n",
    "    :param n_class: number of classes\n",
    "    :param routings: number of routing iterations\n",
    "    :param batch_size: size of batch\n",
    "    :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
    "            `eval_model` can also be used for training.\n",
    "    \"\"\"\n",
    "    x = layers.Input(shape=input_shape, batch_size=batch_size)\n",
    "\n",
    "    # Layer 1: Just a conventional Conv2D layer\n",
    "    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    "\n",
    "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "    primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "\n",
    "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
    "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings, name='digitcaps')(primarycaps)\n",
    "\n",
    "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "    # If using tensorflow, this will not be necessary. :)\n",
    "    out_caps = Length(name='capsnet')(digitcaps)\n",
    "\n",
    "    # Decoder network.\n",
    "    y = layers.Input(shape=(n_class,))\n",
    "    masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
    "    masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
    "\n",
    "    # Shared Decoder model in training and prediction\n",
    "    decoder = models.Sequential(name='decoder')\n",
    "    decoder.add(layers.Dense(512, activation='relu', input_dim=16 * n_class))\n",
    "    decoder.add(layers.Dense(1024, activation='relu'))\n",
    "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "    # Models for training and evaluation (prediction)\n",
    "    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "    eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
    "\n",
    "    # manipulate model\n",
    "    noise = layers.Input(shape=(n_class, 16))\n",
    "    noised_digitcaps = layers.Add()([digitcaps, noise])\n",
    "    masked_noised_y = Mask()([noised_digitcaps, y])\n",
    "    manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
    "    return train_model, eval_model, manipulate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
    "    :param y_true: [None, n_classes]\n",
    "    :param y_pred: [None, num_capsule]\n",
    "    :return: a scalar loss value.\n",
    "    \"\"\"\n",
    "    # return tf.reduce_mean(tf.square(y_pred))\n",
    "    L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n",
    "\n",
    "    return tf.reduce_mean(tf.reduce_sum(L, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import csv\n",
    "import math\n",
    "import pandas\n",
    "\n",
    "def combine_images(generated_images, height=None, width=None):\n",
    "    num = generated_images.shape[0]\n",
    "    if width is None and height is None:\n",
    "        width = int(math.sqrt(num))\n",
    "        height = int(math.ceil(float(num)/width))\n",
    "    elif width is not None and height is None:  # height not given\n",
    "        height = int(math.ceil(float(num)/width))\n",
    "    elif height is not None and width is None:  # width not given\n",
    "        width = int(math.ceil(float(num)/height))\n",
    "\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, 0]\n",
    "    return image\n",
    "\n",
    "def plot_log(filename, show=True):\n",
    "\n",
    "    data = pandas.read_csv(filename)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,6))\n",
    "    fig.subplots_adjust(top=0.95, bottom=0.05, right=0.95)\n",
    "    fig.add_subplot(211)\n",
    "    for key in data.keys():\n",
    "        if key.find('loss') >= 0 and not key.find('val') >= 0:  # training loss\n",
    "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
    "    plt.legend()\n",
    "    plt.title('Training loss')\n",
    "\n",
    "    fig.add_subplot(212)\n",
    "    for key in data.keys():\n",
    "        if key.find('acc') >= 0:  # acc\n",
    "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
    "    plt.legend()\n",
    "    plt.title('Training and validation accuracy')\n",
    "\n",
    "    # fig.savefig('result/log.png')\n",
    "    if show:\n",
    "        plt.show()    \n",
    "\n",
    "def test(model, data, args):\n",
    "    x_test, y_test = data\n",
    "    y_pred, x_recon = model.predict(x_test, batch_size=100)\n",
    "    print('-' * 30 + 'Begin: test' + '-' * 30)\n",
    "    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1)) / y_test.shape[0])\n",
    "\n",
    "    img = combine_images(np.concatenate([x_test[:50], x_recon[:50]]))\n",
    "    image = img * 255\n",
    "    Image.fromarray(image.astype(np.uint8)).save(args.save_dir + \"/real_and_recon.png\")\n",
    "    print()\n",
    "    print('Reconstructed images are saved to %s/real_and_recon.png' % args.save_dir)\n",
    "    print('-' * 30 + 'End: test' + '-' * 30)\n",
    "    plt.imshow(plt.imread(args.save_dir + \"/real_and_recon.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, args):\n",
    "    \"\"\"\n",
    "    Training a CapsuleNet\n",
    "    :param model: the CapsuleNet model\n",
    "    :param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n",
    "    :param args: arguments\n",
    "    :return: The trained model\n",
    "    \"\"\"\n",
    "    # unpacking the data\n",
    "    (x_train, y_train), (x_test, y_test) = data\n",
    "\n",
    "    # callbacks\n",
    "    log = callbacks.CSVLogger(args.save_dir + '/log.csv')\n",
    "    checkpoint = callbacks.ModelCheckpoint(args.save_dir + '/weights-{epoch:02d}.h5', monitor='val_capsnet_accuracy',\n",
    "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
    "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args.lr * (args.lr_decay ** epoch))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer=optimizers.Adam(lr=args.lr),\n",
    "                  loss=[margin_loss, 'mse'],\n",
    "                  loss_weights=[1., args.lam_recon],\n",
    "                  metrics={'capsnet': 'accuracy'})\n",
    "\n",
    "    \"\"\"\n",
    "    # Training without data augmentation:\n",
    "    model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs,\n",
    "              validation_data=[[x_test, y_test], [y_test, x_test]], callbacks=[log, tb, checkpoint, lr_decay])\n",
    "    \"\"\"\n",
    "\n",
    "    # Begin: Training with data augmentation ---------------------------------------------------------------------#\n",
    "    def train_generator(x, y, batch_size, shift_fraction=0.):\n",
    "        train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
    "                                           height_shift_range=shift_fraction)  # shift up to 2 pixel for MNIST\n",
    "        generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
    "        while 1:\n",
    "            x_batch, y_batch = generator.next()\n",
    "            yield (x_batch, y_batch), (y_batch, x_batch)\n",
    "\n",
    "    # Training with data augmentation. If shift_fraction=0., no augmentation.\n",
    "    model.fit(train_generator(x_train, y_train, args.batch_size, args.shift_fraction),\n",
    "              steps_per_epoch=int(y_train.shape[0] / args.batch_size),\n",
    "              epochs=args.epochs,\n",
    "              validation_data=((x_test, y_test), (y_test, x_test)), batch_size=args.batch_size,\n",
    "              callbacks=[log, checkpoint, lr_decay])\n",
    "        \n",
    "    # End: Training with data augmentation -----------------------------------------------------------------------#\n",
    "\n",
    "    model.save_weights(args.save_dir + '/trained_model.h5')\n",
    "    print('Trained model saved to \\'%s/trained_model.h5\\'' % args.save_dir)\n",
    "\n",
    "    plot_log(args.save_dir + '/log.csv', show=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(epochs=10, batch_size=500, lr=0.001, lr_decay=0.9, lam_recon=0.392, routings=1, shift_fraction=0.1, debug=False, save_dir='./result', testing=False, digit=5, weights=None)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Capsule Network on MNIST.\")\n",
    "parser.add_argument('--epochs', default=10, type=int)\n",
    "parser.add_argument('--batch_size', default=500, type=int)\n",
    "parser.add_argument('--lr', default=0.001, type=float,\n",
    "                        help=\"Initial learning rate\")\n",
    "parser.add_argument('--lr_decay', default=0.9, type=float,\n",
    "                        help=\"The value multiplied by lr at each epoch. Set a larger value for larger epochs\")\n",
    "parser.add_argument('--lam_recon', default=0.392, type=float,\n",
    "                        help=\"The coefficient for the loss of decoder\")\n",
    "parser.add_argument('-r', '--routings', default=1, type=int,\n",
    "                        help=\"Number of iterations used in routing algorithm. should > 0\")\n",
    "parser.add_argument('--shift_fraction', default=0.1, type=float,\n",
    "                        help=\"Fraction of pixels to shift at most in each direction.\")\n",
    "parser.add_argument('--debug', action='store_true',\n",
    "                        help=\"Save weights by TensorBoard\")\n",
    "parser.add_argument('--save_dir', default='./result')\n",
    "parser.add_argument('-t', '--testing', action='store_true',\n",
    "                        help=\"Test the trained model on testing dataset\")\n",
    "parser.add_argument('--digit', default=5, type=int,\n",
    "                        help=\"Digit to manipulate\")\n",
    "parser.add_argument('-w', '--weights', default=None,\n",
    "                        help=\"The path of the saved weights. Should be specified when testing\")\n",
    "args, unknown = parser.parse_known_args()\n",
    "print(args)\n",
    "\n",
    "if not os.path.exists(args.save_dir):\n",
    "    os.makedirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist():\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    from tensorflow.keras.datasets import mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
    "    y_train = to_categorical(y_train.astype('float32'))\n",
    "    y_test = to_categorical(y_test.astype('float32'))\n",
    "\n",
    "    # data_slice = 10000\n",
    "    # x_train = x_train[:data_slice,:]\n",
    "    # y_train = y_train[:data_slice,:]\n",
    "    # x_test = x_test[:data_slice,:]\n",
    "    # y_test = y_test[:data_slice,:]\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)       [(500, 28, 28, 1)]           0         []                            \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)              (500, 20, 20, 256)           20992     ['input_10[0][0]']            \n",
      "                                                                                                  \n",
      " primarycap_conv2d (Conv2D)  (500, 6, 6, 256)             5308672   ['conv1[0][0]']               \n",
      "                                                                                                  \n",
      " primarycap_reshape (Reshap  (500, 1152, 8)               0         ['primarycap_conv2d[0][0]']   \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " primarycap_squash (Lambda)  (500, 1152, 8)               0         ['primarycap_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " digitcaps (CapsuleLayer)    (500, 10, 16)                1474560   ['primarycap_squash[0][0]']   \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)       [(None, 10)]                 0         []                            \n",
      "                                                                                                  \n",
      " mask_9 (Mask)               (500, 160)                   0         ['digitcaps[0][0]',           \n",
      "                                                                     'input_11[0][0]']            \n",
      "                                                                                                  \n",
      " capsnet (Length)            (500, 10)                    0         ['digitcaps[0][0]']           \n",
      "                                                                                                  \n",
      " decoder (Sequential)        (None, 28, 28, 1)            1411344   ['mask_9[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8215568 (31.34 MB)\n",
      "Trainable params: 8215568 (31.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " # load data\n",
    "(x_train, y_train), (x_test, y_test) = load_mnist()\n",
    "\n",
    "    # define model\n",
    "model, eval_model, manipulate_model = CapsNet(input_shape=x_train.shape[1:],\n",
    "                                                  n_class=len(np.unique(np.argmax(y_train, 1))),\n",
    "                                                  routings=args.routings,\n",
    "                                                  batch_size=args.batch_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1085, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1179, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 577, in update_state\n        self.build(y_pred, y_true)\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 483, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 631, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 631, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 653, in _get_metric_object\n        y_p_rank = len(y_p.shape.as_list())\n\n    ValueError: as_list() is not defined on an unknown TensorShape.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/scratch/local/cs23e001/Documents/Machine-Learning-and-Deep-Learning/ComputerVision/ImageClassification/LargeNetwork/CapsuleNetwork/trial.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.24.6.72/scratch/local/cs23e001/Documents/Machine-Learning-and-Deep-Learning/ComputerVision/ImageClassification/LargeNetwork/CapsuleNetwork/trial.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train(model\u001b[39m=\u001b[39;49mmodel, data\u001b[39m=\u001b[39;49m((x_train, y_train), (x_test, y_test)), args\u001b[39m=\u001b[39;49margs)\n",
      "\u001b[1;32m/scratch/local/cs23e001/Documents/Machine-Learning-and-Deep-Learning/ComputerVision/ImageClassification/LargeNetwork/CapsuleNetwork/trial.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.24.6.72/scratch/local/cs23e001/Documents/Machine-Learning-and-Deep-Learning/ComputerVision/ImageClassification/LargeNetwork/CapsuleNetwork/trial.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m         \u001b[39myield\u001b[39;00m (x_batch, y_batch), (y_batch, x_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.24.6.72/scratch/local/cs23e001/Documents/Machine-Learning-and-Deep-Learning/ComputerVision/ImageClassification/LargeNetwork/CapsuleNetwork/trial.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Training with data augmentation. If shift_fraction=0., no augmentation.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.24.6.72/scratch/local/cs23e001/Documents/Machine-Learning-and-Deep-Learning/ComputerVision/ImageClassification/LargeNetwork/CapsuleNetwork/trial.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_generator(x_train, y_train, args\u001b[39m.\u001b[39;49mbatch_size, args\u001b[39m.\u001b[39;49mshift_fraction),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.24.6.72/scratch/local/cs23e001/Documents/Machine-Learning-and-Deep-Learning/ComputerVision/ImageClassification/LargeNetwork/CapsuleNetwork/trial.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m         \u001b[39m#   steps_per_epoch=int(y_train.shape[0] / args.batch_size),\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.24.6.72/scratch/local/cs23e001/Documents/Machine-Learning-and-Deep-Learning/ComputerVision/ImageClassification/LargeNetwork/CapsuleNetwork/trial.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m           epochs\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mepochs,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.24.6.72/scratch/local/cs23e001/Documents/Machine-Learning-and-Deep-Learning/ComputerVision/ImageClassification/LargeNetwork/CapsuleNetwork/trial.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m           validation_data\u001b[39m=\u001b[39;49m((x_test, y_test), (y_test, x_test)), batch_size\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.24.6.72/scratch/local/cs23e001/Documents/Machine-Learning-and-Deep-Learning/ComputerVision/ImageClassification/LargeNetwork/CapsuleNetwork/trial.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m           callbacks\u001b[39m=\u001b[39;49m[log, checkpoint, lr_decay])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.24.6.72/scratch/local/cs23e001/Documents/Machine-Learning-and-Deep-Learning/ComputerVision/ImageClassification/LargeNetwork/CapsuleNetwork/trial.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# End: Training with data augmentation -----------------------------------------------------------------------#\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.24.6.72/scratch/local/cs23e001/Documents/Machine-Learning-and-Deep-Learning/ComputerVision/ImageClassification/LargeNetwork/CapsuleNetwork/trial.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m model\u001b[39m.\u001b[39msave_weights(args\u001b[39m.\u001b[39msave_dir \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/trained_model.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filedh9fwouc.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1085, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1179, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 577, in update_state\n        self.build(y_pred, y_true)\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 483, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 631, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 631, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/home/cs23e001/.conda/envs/GPU_CS23E001/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 653, in _get_metric_object\n        y_p_rank = len(y_p.shape.as_list())\n\n    ValueError: as_list() is not defined on an unknown TensorShape.\n"
     ]
    }
   ],
   "source": [
    "train(model=model, data=((x_train, y_train), (x_test, y_test)), args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_CS23E001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
